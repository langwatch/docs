---
title: "Data Model"
description: "Understand the structure of prompts in LangWatch"
---

# Prompt Data Model

This page explains the structure of prompts in LangWatch and how they're organized.

## Overview

Prompts in LangWatch are organized with a two-level structure:

- **Prompt Configuration**: The main prompt entity with metadata
- **Prompt Versions**: Individual versions of the prompt content

## Prompt Configuration

Each prompt has a configuration that contains metadata and references to its versions.

```json
{
  "id": "prompt_TrYXZLsiTJkn9N6PiZiae",
  "handle": "customer-support-bot",
  "scope": "PROJECT",
  "projectId": "proj_123",
  "organizationId": null,
  "createdAt": "2024-01-15T10:30:00Z",
  "updatedAt": "2024-01-15T10:30:00Z",
  "deletedAt": null
}
```

### Fields

- **`id`**: Unique identifier for the prompt
- **`handle`**: Optional globally unique identifier
- **`scope`**: Either `"PROJECT"` (default) or `"ORGANIZATION"` for shared prompts
- **`projectId`**: The project this prompt belongs to
- **`organizationId`**: The organization this prompt belongs to (null for project scope)
- **`createdAt`**: When the prompt was created
- **`updatedAt`**: When the prompt was last updated
- **`deletedAt`**: Soft delete timestamp (null if not deleted)

### Config Data Fields

- **`version`**: Version number within the config data
- **`prompt`**: The main prompt text with variable placeholders
- **`messages`**: Array of chat messages with roles and content
- **`inputs`**: Array of input variable definitions with identifiers and types
- **`outputs`**: Array of output variable definitions with identifiers and types
- **`model`**: The LLM model to use (e.g., `"openai/gpt-5"`) - model names follow the litellm structure ("provider/model")
- **`temperature`**: Optional temperature setting for the model
- **`max_tokens`**: Optional maximum token limit
- **`demonstrations`**: Optional few-shot examples with columns and rows structure

### Demonstrations Structure

The `demonstrations` field supports few-shot learning with example inputs and outputs:

```json
{
  "demonstrations": {
    "columns": [
      {
        "id": "input",
        "name": "User Input",
        "type": "string"
      },
      {
        "id": "output",
        "name": "Expected Output",
        "type": "string"
      }
    ],
    "rows": [
      {
        "id": "example_1",
        "input": "I need help with my account",
        "output": "I'd be happy to help you with your account. What specific issue are you experiencing?"
      },
      {
        "id": "example_2",
        "input": "How do I reset my password?",
        "output": "To reset your password, please visit our password reset page or contact support for assistance."
      }
    ]
  }
}
```

**Column Types:**

- `"string"` - Text data
- `"boolean"` - True/false values
- `"number"` - Numeric data
- `"date"` - Date/time values
- `"list"` - Array data
- `"json"` - JSON objects
- `"spans"` - Trace span data
- `"rag_contexts"` - RAG context data
- `"chat_messages"` - Chat message arrays
- `"annotations"` - Annotation data
- `"evaluations"` - Evaluation results

## Variable Formatting

Prompts use `{{ variable_name }}` syntax for dynamic content:

```text
You are a helpful customer support agent. The user is {{user_name}} and their email is {{user_email}}.

Please help them with: {{input}}
```

### Supported Variable Types

- **Strings**: `{{user_name}}`
- **Numbers**: `{{count}}`
- **Booleans**: `{{is_premium}}`
- **Lists**: `{{items}}`
- **Objects**: `{{user_data}}` (will be converted to string)

### Input/Output Type System

The `inputs` and `outputs` arrays define the expected variable types:

**Input Types:**

- `"str"` - String values
- `"float"` - Floating point numbers
- `"bool"` - Boolean values
- `"image"` - Image data
- `"list[str]"` - List of strings
- `"list[float]"` - List of floats
- `"list[int]"` - List of integers
- `"list[bool]"` - List of booleans
- `"dict"` - Dictionary/object

**Output Types:**

- `"str"` - String responses
- `"float"` - Numeric responses
- `"bool"` - Boolean responses
- `"json_schema"` - Structured JSON responses

## API Response Format

When retrieving a prompt via API, you get the latest version of the prompt configuration:

```json
{
  "id": "prompt_TrYXZLsiTJkn9N6PiZiae",
  "handle": "customer-support-bot",
  "scope": "PROJECT",
  "projectId": "proj_123",
  "organizationId": "org_456",
  "version": 1,
  "versionId": "version_abc123",
  "createdAt": "2024-01-15T10:30:00Z",
  "updatedAt": "2024-01-15T10:30:00Z",
  "authorId": "user_789",
  "model": "openai/gpt-4o-mini",
  "prompt": "You are a helpful customer support agent...",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful customer support agent"
    },
    {
      "role": "user",
      "content": "{{input}}"
    }
  ],
  "inputs": [
    {
      "identifier": "input",
      "type": "str"
    }
  ],
  "outputs": [
    {
      "identifier": "response",
      "type": "str"
    }
  ],
  "temperature": 0.7,
  "maxTokens": 1000,
  "responseFormat": {
    "type": "text"
  },
  "demonstrations": null,
  "promptingTechnique": null
}
```

## Field Descriptions

### Core Fields

- **`id`** - Unique identifier for the prompt
- **`handle`** - Human-readable identifier (can be null)
- **`scope`** - Either "PROJECT" or "ORGANIZATION"
- **`projectId`** - ID of the project that owns the prompt
- **`organizationId`** - ID of the organization

### Version Fields

- **`version`** - Current version number
- **`versionId`** - Unique identifier for this version
- **`createdAt`** - When this version was created
- **`updatedAt`** - When the prompt was last updated
- **`authorId`** - ID of the user who created this version

### Content Fields

- **`prompt`** - The main prompt text (system message)
- **`messages`** - Array of conversation messages
- **`inputs`** - Array of input variable definitions
- **`outputs`** - Array of output variable definitions
- **`model`** - The LLM model identifier

### Configuration Fields

- **`temperature`** - Model temperature setting (optional)
- **`maxTokens`** - Maximum token limit (optional)
- **`responseFormat`** - Response format configuration
- **`demonstrations`** - Few-shot examples (optional)
- **`promptingTechnique`** - Advanced prompting technique (optional)

## Scope and Access

### Project Scope (Default)

- Prompts are only accessible within the project
- `scope: "PROJECT"`
- `organizationId: null`

### Organization Scope

- Prompts are shared across all projects in the organization
- `scope: "ORGANIZATION"`
- `organizationId: "org_456"`

<Note>Only the original project can modify a shared prompt</Note>

## Version Management

- Each prompt starts with version 1
- New versions increment the version number
- The latest version is automatically used
- You can retrieve specific versions by version number
- Version history is preserved for rollback

---

[‚Üê Back to Prompt Management Overview](/prompt-management/overview)
