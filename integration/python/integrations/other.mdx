---
title: Other OpenTelemetry Instrumentors
sidebarTitle: Other
description: Use any OpenTelemetry-compatible instrumentor with LangWatch to standardize tracing and centralize AI agent testing observability.
keywords: opentelemetry, instrumentation, custom, other, generic, BaseInstrumentor, LangWatch, Python
---

LangWatch is designed to be compatible with the broader OpenTelemetry ecosystem. Beyond the specifically documented integrations, you can use LangWatch with any Python library that has an OpenTelemetry instrumentor, provided that the instrumentor adheres to the standard OpenTelemetry Python `BaseInstrumentor` interface.

## Using Custom/Third-Party OpenTelemetry Instrumentors

If you have a specific library you want to trace, and there's an OpenTelemetry instrumentor available for it (either a community-provided one not yet listed in our specific integrations, or one you've developed yourself), you can integrate it with LangWatch.

The key is that the instrumentor should be an instance of a class that inherits from `opentelemetry.instrumentation.instrumentor.BaseInstrumentor`. You can find the official documentation for this base class here:

- [OpenTelemetry BaseInstrumentor Documentation](https://opentelemetry-python-contrib.readthedocs.io/en/latest/instrumentation/base/instrumentor.html#opentelemetry.instrumentation.instrumentor.BaseInstrumentor)

### Integration via `langwatch.setup()`

To use such an instrumentor, you simply pass an instance of it to the `instrumentors` list in the `langwatch.setup()` call. LangWatch will then manage its lifecycle (calling its `instrument()` and `uninstrument()` methods appropriately).

Here's a conceptual example using the OpenTelemetry `LoggingInstrumentor`:

```python
import langwatch
import os
import logging # Standard Python logging

# Import an off-the-shelf OpenTelemetry instrumentor
# Ensure you have this package installed: pip install opentelemetry-instrumentation-logging
from opentelemetry.instrumentation.logging import LoggingInstrumentor

# Ensure LANGWATCH_API_KEY is set in your environment, or set it in `setup`
langwatch.setup(
    instrumentors=[
        LoggingInstrumentor() # Pass an instance of the instrumentor
    ]
)

# Configure standard Python logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
# You might want to add a handler if you also want to see logs in the console
# handler = logging.StreamHandler()
# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
# handler.setFormatter(formatter)
# logger.addHandler(handler)

@langwatch.trace(name="Task with Instrumented Logging")
def perform_task_with_logging():
    logger.info("Starting the task.")
    # ... some work ...
    logger.warning("Something to be aware of happened during the task.")
    # ... more work ...
    logger.info("Task completed.")
    return "Task finished successfully"

if __name__ == "__main__":
    print("Running example with LoggingInstrumentor...")
    result = perform_task_with_logging()
    print(f"Result: {result}")
    # Spans for the log messages (e.g., logger.info, logger.warning)
    # would be generated by LoggingInstrumentor and captured by LangWatch.
```

When this code runs, the `LoggingInstrumentor` (managed by `langwatch.setup()`) will automatically create OpenTelemetry spans for any log messages emitted by the standard Python `logging` module. LangWatch will then capture these spans.

## Discovering More Community Instrumentors

Many Python libraries, especially in the AI/ML space, are instrumented by community-driven OpenTelemetry projects. If you're looking for pre-built instrumentors, these are excellent places to start:

*   **OpenInference (by Arize AI):** [https://github.com/Arize-ai/openinference](https://github.com/Arize-ai/openinference)
    *   This project provides instrumentors for a wide range of AI/ML libraries and frameworks. Examples include:
        *   OpenAI
        *   Anthropic
        *   LiteLLM
        *   Haystack
        *   LlamaIndex
        *   LangChain
        *   Groq
        *   Google Gemini
        *   And more (check their repository for the full list).

*   **OpenLLMetry (by Traceloop):** [https://github.com/traceloop/openllmetry](https://github.com/traceloop/openllmetry)
    *   This project also offers a comprehensive suite of instrumentors for LLM applications and related tools. Examples include:
        *   OpenAI
        *   CrewAI
        *   Haystack
        *   LangChain
        *   LlamaIndex
        *   Pinecone
        *   ChromaDB
        *   And more (explore their repository for details).

You can browse these repositories to find instrumentors for other libraries you might be using. If an instrumentor from these projects (or any other source) adheres to the `BaseInstrumentor` interface, you can integrate it with LangWatch using the `langwatch.setup(instrumentors=[...])` method described above.

### Key Considerations:

1.  **`BaseInstrumentor` Compliance:** Ensure the instrumentor correctly implements the `BaseInstrumentor` interface, particularly the `instrument()` and `uninstrument()` methods, and `instrumentation_dependencies()`.
2.  **Installation:** You'll need to have the custom instrumentor package installed in your Python environment, along with the library it instruments.
3.  **TracerProvider:** LangWatch configures an OpenTelemetry `TracerProvider`. The instrumentor, when activated by LangWatch, will use this provider to create spans. If you are managing your OpenTelemetry setup more directly (e.g., providing your own `TracerProvider` to `langwatch.setup()`), the instrumentor will use that instead.
4.  **Data Quality:** The quality and detail of the telemetry data captured will depend on how well the custom instrumentor is written.

By leveraging the `BaseInstrumentor` interface, LangWatch remains flexible and extensible, allowing you to bring telemetry from a wide array of Python libraries into your observability dashboard.
