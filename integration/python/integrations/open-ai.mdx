---
title: OpenAI Instrumentation
sidebarTitle: Python
description: Learn how to instrument OpenAI API calls with the LangWatch Python SDK
icon: python
keywords: openai, instrumentation, autotrack, langwatch, python
---

LangWatch integrates with OpenAI to automatically capture detailed information about your LLM calls.

## Installation

<CodeGroup>
```bash pip
pip install langwatch openai
```

```bash uv
uv add langwatch openai
```
</CodeGroup>

## Usage

<Info>
The LangWatch API key is configured by default via the `LANGWATCH_API_KEY` environment variable.
</Info>

Use `autotrack_openai_calls()` to automatically capture all OpenAI calls made with a specific client instance within a trace.

```python
import langwatch
from openai import OpenAI

langwatch.setup()
client = OpenAI()


@langwatch.trace(name="OpenAI Chat Completion")
def get_openai_chat_response(user_prompt: str):
    langwatch.get_current_trace().autotrack_openai_calls(client)

    response = client.chat.completions.create(
        model="gpt-5",
        messages=[{"role": "user", "content": user_prompt}],
    )
    completion = response.choices[0].message.content
    return completion


if __name__ == "__main__":
    user_query = "Tell me a joke"
    response = get_openai_chat_response(user_query)

    print(f"User: {user_query}")
    print(f"AI: {response}")
```

The `@langwatch.trace()` decorator creates a parent trace, and `autotrack_openai_calls()` enables automatic tracking of all calls made with the specified client instance for the duration of that trace.

## Related

- [Capturing RAG](/integration/python/tutorials/capturing-rag) - Learn how to capture RAG data from retrievers and tools
- [Capturing Metadata and Attributes](/integration/python/tutorials/capturing-metadata) - Add custom metadata and attributes to your traces and spans
- [Capturing Evaluations & Guardrails](/integration/python/tutorials/capturing-evaluations-guardrails) - Log evaluations and implement guardrails in your OpenAI applications
