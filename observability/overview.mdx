---
title: "Observability & Tracing"
description: "Monitor, debug, and optimize your LLM applications with comprehensive observability and tracing capabilities"
sidebarTitle: Overview
keywords: observability, tracing, langwatch, llm, ai, monitoring
---

See what's happening inside your LLM applications. LangWatch tracks every interaction, helps you debug issues, and shows you how your AI systems actually work in production.

<Frame>
  <img
    className="block"
    src="/images/llm-observability/overview.webp"
    alt="LangWatch Observability Dashboard"
  />
</Frame>

## Core Features

<CardGroup cols={3}>
  <Card
    title="Real-time Tracing"
    description="Watch every LLM call and tool usage as it happens, with full context."
    icon="chart-network"
    href="/concepts"
    horizontal
    arrow
  />
  <Card
    title="User Events"
    description="See how users actually interact with your AI - thumbs up, selections, custom events."
    icon="users"
    href="/user-events/overview"
    horizontal
    arrow
  />
  <Card
    title="Cost Tracking"
    description="Know exactly how much each model call costs you, down to the token."
    icon="dollar-sign"
    href="/integration/python/tutorials/tracking-llm-costs"
    horizontal
    arrow
  />
  <Card
    title="Monitor Performance"
    description="Spot slow calls and bottlenecks before your users complain."
    icon="gauge"
  />
  <Card
    title="Triggers & Alerts"
    description="Get notified when things go wrong, or when costs spike unexpectedly."
    icon="bell"
    href="/features/triggers"
    horizontal
    arrow
  />
  <Card
    title="Embedded Analytics"
    description="Drop dashboards right into your app so your team can see what's happening."
    icon="chart-bar"
    href="/features/embedded-analytics"
    horizontal
    arrow
  />
</CardGroup>

## How it works

Add a few lines to your code and LangWatch starts tracking everything:

1. **Add the SDK** - Drop in a few lines of code to your existing app
2. **We track everything** - Automatically captures all your LLM calls and interactions
3. **See it live** - Watch what's happening in real-time through the dashboard
4. **Debug easily** - Click into any trace to see exactly what went wrong

## Get started

Pick your language and start tracking:

<CardGroup cols={2}>
  <Card
    title="Python SDK"
    icon="python"
	href="/integration/python/guide"
	horizontal
	arrow
  />
  <Card
    title="TypeScript SDK"
    icon="code"
    href="/integration/typescript/guide"
	horizontal
	arrow
  />
  <Card
    title="Go SDK"
    icon="golang"
    href="/integration/go/guide"
	horizontal
	arrow
  />
  <Card
    title="View All Integrations"
    icon="plug"
    href="/integration/overview"
	horizontal
	arrow
  />
</CardGroup>
