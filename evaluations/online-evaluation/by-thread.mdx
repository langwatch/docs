---
title: Evaluation by Thread
description: Evaluate LLM applications by thread in LangWatch to analyze conversation-level performance in agent testing setups.
---

With LangWatch, you can evaluate your LLM applications by thread. This approach is useful for analyzing the performance of your LLM applications across entire conversation threads, helping you identify which threads are performing well or poorly.

To set up evaluation by thread, toggle the thread-based mapping option when creating an evaluation.

<Frame>
<img className="block" src="/images/dataset-thread-evaluation.png" alt="LangWatch Evaluation by Thread" />
</Frame>

This enables thread-based evaluation where each time a trace is evaluated, the full thread context is retrieved and passed to the evaluation function. This approach builds upon the complete conversation thread rather than individual traces.

By default, we include the trace INPUT and OUTPUT fields in the evaluation. You can add additional fields to the evaluation by including them in your dataset.