---
title: List of Evaluators
description: Browse all available evaluators in LangWatch to find the right scoring method for your AI agent evaluation use case.
---

LangWatch offers an extensive library of evaluators to help you evaluate the quality and guarantee the safety of your LLM apps.

While here you can find a reference list, to get the execution code you can use the [Experiments via UI](https://app.langwatch.ai/@project/evaluations) on LangWatch platform.

<Card title="Evaluators API Reference" icon="code" href="/api-reference/evaluators/overview">
  Full API documentation for running evaluations programmatically.
</Card>

## Evaluators List

import EvaluatorsList from "/snippets/evaluators-list.mdx"

<EvaluatorsList />

## Running Evaluations

Set up your first evaluation using the [Experiments via UI](https://app.langwatch.ai/@project/evaluations):

<a href="https://app.langwatch.ai/@project/evaluations" target="_blank">
<Frame>
<img src="/images/offline-evaluation/Screenshot_2025-04-17_at_16.53.38.png" alt="" style={{ maxWidth: '400px' }} noZoom />
</Frame>
</a>

## Instrumenting Custom Evaluator

If you have a custom evaluator built in-house, you can follow the guide below to integrate.

<CardGroup cols={1}>
  <Card
    title="Instrumenting Custom Evaluator"
    icon="link"
    href="/evaluations/evaluators/custom-evaluators"
  />
</CardGroup>
