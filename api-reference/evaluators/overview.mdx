---
title: 'Overview'
description: 'Browse all available evaluators in LangWatch to find the right scoring method for your AI agent evaluation use case.'
---

## Intro

LangWatch offers an extensive library of evaluators to help you evaluate the quality and guarantee the safety of your LLM apps.

While here you can find a reference list, to get the execution code you can use the [Evaluation Wizard](https://app.langwatch.ai/@project/evaluations) on LangWatch platform.

## Authentication

To make a call to the Evaluators API, you will need to pass through your LangWatch API key in the header as `X-Auth-Token`. Your API key can be found on the setup page under settings.

#### Allowed Methods

- `POST /api/evaluations/{evaluator}/evaluate` - Run an evaluation using a specific evaluator

## Evaluators List

import EvaluatorsList from "/snippets/evaluators-list.mdx"

<EvaluatorsList />

## Running Evaluations

Set up your first evaluation using the [Evaluation Wizard](https://app.langwatch.ai/@project/evaluations):

<a href="https://app.langwatch.ai/@project/evaluations" target="_blank">
<Frame>
<img src="/images/offline-evaluation/Screenshot_2025-04-17_at_16.53.38.png" alt="" style={{ maxWidth: '400px' }} noZoom />
</Frame>
</a>

## Instrumenting Custom Evaluator

If you have a custom evaluator built in-house, you can follow the guide below to integrate.

<CardGroup cols={1}>
  <Card
    title="Instrumenting Custom Evaluator"
    icon="link"
    href="/evaluations/custom-evaluator-integration"
  />
</CardGroup>

## Common Request Format

All evaluator endpoints follow a similar pattern:

```
POST /api/evaluations/{evaluator_path}/evaluate
```

Each evaluator accepts specific input parameters and settings. Refer to the individual evaluator documentation pages for detailed request/response schemas and examples.

## Response Format

Successful evaluations return an array of evaluation results with scores, details, and metadata specific to each evaluator type.
